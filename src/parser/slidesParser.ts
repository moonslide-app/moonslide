// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
export const parser = LRParser.deserialize({
  version: 14,
  states: "$OQQOPOOOOOO'#C`'#C`OVOPO'#C_ObOPO'#C^OgOPO'#ChQQOPOOOOOO'#Ci'#CiOuOPO'#CbOOOO,58y,58yO!QOPO,58xOVOPO'#CfO!]OPO'#CjO!bOPO'#CgOOOO,59S,59SOOOO-E6f-E6fOOOO-E6g-E6gO!pOPO'#CeOQOPO1G.dOOOO,59Q,59QOOOO,59U,59UOOOO-E6h-E6hO!{OPO7+$OOOOO<<Gj<<Gj",
  stateData: "#V~OTPO~OTUOVUOWUP~OWXO~OVYOTZPWYP_ZP~OTUOVUOWUX~OVYOTXPWYP~OWcO~OVYOTZXWYP_ZX~OVYOTXXWYP~OWfO~OTWVW~",
  goto: "!k_PP`dkPpPPvy!P!S!Y!aTSOTSROTReaVQOTaQWQRbYRaXXZSX[`R]SQTOR^TSVQYR_VQ[SQ`XTd[`",
  nodeNames: "âš  T YamlBlock DelimiterStartLine StartDelimiter Delimiter AnyContentLine Any Break YamlContent NoDelimiterStartLine MarkdownContent",
  maxTerm: 15,
  skippedNodes: [0],
  repeatNodeCount: 3,
  tokenData: "!_~RVOYhYZmZ}h}!Ot!O;'Sh;'S;=`!X<%lOh~mOV~~tOW~V~~yPV~}!O|~!PP}!O!S~!XOT~~![P;=`<%lh",
  tokenizers: [0],
  topRules: {"T":[0,1]},
  tokenPrec: 94
})
